{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJqdoXLGOLzS",
        "outputId": "8e2dd1d3-ab4b-47e5-c9e1-0f9c2ba380c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.2.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.8.3)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.3)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "dataset_url = 'https://www.kaggle.com/datasets/mnkbiswas/anime-face-with-eye-and-hair-color-tagged'\n",
        "od.download(dataset_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LIZrAm-OWeP",
        "outputId": "fa71fe23-c99f-4345-96a6-5a676dae63f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mnkbiswas/anime-face-with-eye-and-hair-color-tagged\n",
            "Downloading anime-face-with-eye-and-hair-color-tagged.zip to ./anime-face-with-eye-and-hair-color-tagged\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 457M/457M [00:00<00:00, 494MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "\n",
        "file_path = \"/content/anime-face-with-eye-and-hair-color-tagged/data.tgz\"        # your tgz file\n",
        "extract_path = \"/content/anime_dataset\"  # folder to extract into\n",
        "\n",
        "# Create folder if not exists\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract .tgz file\n",
        "with tarfile.open(file_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "print(\"✅ Extraction completed!\")\n",
        "print(\"Files extracted:\", os.listdir(extract_path)[:20])  # show first 20 files\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBG464hcOaNt",
        "outputId": "7f79d864-9082-416a-b561-a75710d8ff4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-483798125.py:12: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=extract_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction completed!\n",
            "Files extracted: ['data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only needed in Colab\n",
        "!pip install tensorflow pandas pillow tqdm\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print(\"✅ TensorFlow version:\", tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2u9a10OuOd_H",
        "outputId": "888a8396-6ff8-4a16-96bd-0958fabab7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "✅ TensorFlow version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/anime_dataset/data/tags.csv\"\n",
        "image_dir = \"/content/anime_dataset/data/images\"\n",
        "\n",
        "df = pd.read_csv(csv_path, header=None)\n",
        "df.columns = [\"image_id\", \"tags\"]\n",
        "df[\"tags\"] = df[\"tags\"].str.lower()\n",
        "\n",
        "# Extract hair & eye colors\n",
        "df[[\"hair_color\",\"eye_color\"]] = df[\"tags\"].str.extract(r\"(\\w+) hair (\\w+) eyes\")\n",
        "df.dropna(subset=[\"hair_color\",\"eye_color\"], inplace=True)\n",
        "\n",
        "df[\"image_name\"] = df[\"image_id\"].astype(str) + \".jpg\"\n",
        "\n",
        "# Map labels\n",
        "hair2idx = {hair: idx for idx, hair in enumerate(df[\"hair_color\"].unique())}\n",
        "eye2idx = {eye: idx for idx, eye in enumerate(df[\"eye_color\"].unique())}\n",
        "\n",
        "df[\"hair_label\"] = df[\"hair_color\"].map(hair2idx).astype(int)\n",
        "df[\"eye_label\"] = df[\"eye_color\"].map(eye2idx).astype(int)\n",
        "\n",
        "num_hairs = len(hair2idx)\n",
        "num_eyes = len(eye2idx)\n",
        "cond_dim = num_hairs + num_eyes\n",
        "\n",
        "print(\"Hair colors:\", hair2idx)\n",
        "print(\"Eye colors:\", eye2idx)\n",
        "print(\"Total condition dim:\", cond_dim)\n",
        "print(\"Number of images:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-ccsUeFPgs8",
        "outputId": "4000bcdd-b97b-4650-b30d-2a77bc5370ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hair colors: {'aqua': 0, 'gray': 1, 'green': 2, 'orange': 3, 'red': 4, 'white': 5, 'black': 6, 'blonde': 7, 'blue': 8, 'brown': 9, 'pink': 10, 'purple': 11}\n",
            "Eye colors: {'aqua': 0, 'black': 1, 'blue': 2, 'brown': 3, 'green': 4, 'orange': 5, 'pink': 6, 'purple': 7, 'red': 8, 'yellow': 9}\n",
            "Total condition dim: 22\n",
            "Number of images: 36740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 64\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def load_image(img_name):\n",
        "    path = os.path.join(image_dir, img_name)\n",
        "    img = Image.open(path).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    img = np.array(img).astype(\"float32\") / 127.5 - 1.0  # Normalize [-1,1]\n",
        "    return img\n",
        "\n",
        "def make_condition_vector(row):\n",
        "    hair = np.zeros(num_hairs, dtype=np.float32)\n",
        "    hair[row[\"hair_label\"]] = 1\n",
        "    eye = np.zeros(num_eyes, dtype=np.float32)\n",
        "    eye[row[\"eye_label\"]] = 1\n",
        "    return np.concatenate([hair, eye], axis=0)\n",
        "\n",
        "images = []\n",
        "conditions = []\n",
        "\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    try:\n",
        "        img = load_image(row[\"image_name\"])\n",
        "        cond = make_condition_vector(row)\n",
        "        images.append(img)\n",
        "        conditions.append(cond)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "images = np.array(images)\n",
        "conditions = np.array(conditions)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((images, conditions))\n",
        "dataset = dataset.shuffle(1000).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(\"✅ Dataset ready:\", images.shape, conditions.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxFzVWMPl-t",
        "outputId": "8fb09200-9dc1-4677-f729-3c7bb6a953ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36740/36740 [00:18<00:00, 2019.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset ready: (36740, 64, 64, 3) (36740, 22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(noise_dim, cond_dim):\n",
        "    cond_input = layers.Input(shape=(cond_dim,))\n",
        "    cond_emb = layers.Dense(32, activation=\"relu\")(cond_input)\n",
        "\n",
        "    noise_input = layers.Input(shape=(noise_dim,))\n",
        "    x = layers.Concatenate()([noise_input, cond_emb])\n",
        "\n",
        "    x = layers.Dense(8*8*256, use_bias=False)(x)\n",
        "    x = layers.Reshape((8, 8, 256))(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(64, 4, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "\n",
        "    out = layers.Conv2DTranspose(3, 4, strides=2, padding=\"same\", activation=\"tanh\")(x)\n",
        "\n",
        "    return tf.keras.Model([noise_input, cond_input], out, name=\"Generator\")\n"
      ],
      "metadata": {
        "id": "4hig05THPxRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(cond_dim):\n",
        "    img_input = layers.Input(shape=(64,64,3))\n",
        "    cond_input = layers.Input(shape=(cond_dim,))\n",
        "\n",
        "    cond_map = layers.Dense(64*64, activation=\"relu\")(cond_input)\n",
        "    cond_map = layers.Reshape((64,64,1))(cond_map)\n",
        "\n",
        "    x = layers.Concatenate()([img_input, cond_map])\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding=\"same\")(x); x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding=\"same\")(x); x = layers.LeakyReLU(0.2)(x)\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding=\"same\")(x); x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    return tf.keras.Model([img_input, cond_input], out, name=\"Discriminator\")\n"
      ],
      "metadata": {
        "id": "BqqxvfDzPy4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise_dim = 100\n",
        "generator = build_generator(noise_dim, cond_dim)\n",
        "discriminator = build_discriminator(cond_dim)\n",
        "\n",
        "bce = tf.keras.losses.BinaryCrossentropy()\n",
        "opt_G = Adam(0.0002, beta_1=0.5)\n",
        "opt_D = Adam(0.0002, beta_1=0.5)\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_img, cond):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "\n",
        "    # Train Discriminator\n",
        "    with tf.GradientTape() as tape_D:\n",
        "        fake_img = generator([noise, cond], training=True)\n",
        "        real_out = discriminator([real_img, cond], training=True)\n",
        "        fake_out = discriminator([fake_img, cond], training=True)\n",
        "\n",
        "        d_loss_real = bce(tf.ones_like(real_out), real_out)\n",
        "        d_loss_fake = bce(tf.zeros_like(fake_out), fake_out)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "    grads_D = tape_D.gradient(d_loss, discriminator.trainable_variables)\n",
        "    opt_D.apply_gradients(zip(grads_D, discriminator.trainable_variables))\n",
        "\n",
        "    # Train Generator\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    with tf.GradientTape() as tape_G:\n",
        "        fake_img = generator([noise, cond], training=True)\n",
        "        fake_out = discriminator([fake_img, cond], training=True)\n",
        "        g_loss = bce(tf.ones_like(fake_out), fake_out)\n",
        "\n",
        "    grads_G = tape_G.gradient(g_loss, generator.trainable_variables)\n",
        "    opt_G.apply_gradients(zip(grads_G, generator.trainable_variables))\n",
        "\n",
        "    return d_loss, g_loss\n",
        "\n",
        "def train(dataset, epochs=5):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        for real_img, cond in tqdm(dataset):\n",
        "            d_loss, g_loss = train_step(real_img, cond)\n",
        "        print(f\"✅ Epoch {epoch+1} | D_loss: {d_loss.numpy():.4f}, G_loss: {g_loss.numpy():.4f}\")\n"
      ],
      "metadata": {
        "id": "OOj2XMjXP14z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(dataset, epochs=20)\n",
        "\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "generator.save(\"models/generator_CGAN.h5\")\n",
        "print(\"✅ Generator saved at models/generator_CGAN.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y7fH7aSWP8iv",
        "outputId": "f06d0743-9ab0-46a2-8db0-481617a76cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:35<00:00, 16.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 1 | D_loss: 1.0509, G_loss: 1.4792\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 2 | D_loss: 0.9579, G_loss: 1.2410\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 3 | D_loss: 1.1683, G_loss: 1.7398\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 4 | D_loss: 0.9149, G_loss: 1.1144\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 5 | D_loss: 1.2779, G_loss: 1.5369\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 6 | D_loss: 0.9644, G_loss: 1.2400\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:40<00:00, 14.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 7 | D_loss: 0.9352, G_loss: 1.6072\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:31<00:00, 18.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 8 | D_loss: 1.2687, G_loss: 0.7346\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:31<00:00, 18.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 9 | D_loss: 1.2503, G_loss: 1.2792\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 10 | D_loss: 0.8905, G_loss: 1.1855\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 11 | D_loss: 1.0071, G_loss: 1.1824\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 12 | D_loss: 1.4253, G_loss: 1.7229\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 13 | D_loss: 1.0394, G_loss: 1.3815\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 14 | D_loss: 1.2304, G_loss: 0.8940\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 15 | D_loss: 1.0907, G_loss: 1.3877\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 16 | D_loss: 0.9336, G_loss: 1.4606\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 17 | D_loss: 0.9894, G_loss: 0.6598\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 18 | D_loss: 0.8725, G_loss: 1.2998\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 19 | D_loss: 0.9725, G_loss: 0.7978\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 574/574 [00:30<00:00, 18.63it/s]\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 20 | D_loss: 0.8701, G_loss: 0.8582\n",
            "✅ Generator saved at models/generator_CGAN.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator.save(\"models/generator_tf.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYXooVQsRtPw",
        "outputId": "7bb028e4-d7c0-457d-a5c0-3aa932034050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}